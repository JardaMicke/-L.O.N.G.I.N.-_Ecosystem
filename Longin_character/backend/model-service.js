/**
 * Slu쬭a pro pr치ci s AI modely
 * Zpracov치v치 generov치n칤 odpov캩d칤 od AI postav
 */
const axios = require('axios');
const logger = require('./utils/logger'); // Professional logging

class ModelService {
  constructor() {
    this.apiEndpoints = {
      openai: 'https://api.openai.com/v1/chat/completions',
      claude: 'https://api.anthropic.com/v1/messages',
      local: 'http://localhost:11434/api/generate' // Ollama endpoint
    };
    this.defaultModel = 'local'; // Pou쮂셨at lok치ln칤 model jako v칳choz칤
    this.retryProviders = ['local', 'openai', 'claude']; // Po콏ad칤 pro retry
    this.maxRetries = 3;
    this.retryDelay = 1000; // 1 sekunda
  }

  /**
   * Generuje odpov캩캞 od AI modelu s automatick칳m retry mechanismem
   * @param {string} prompt - Vstupn칤 prompt
   * @param {object} options - Mo쬹osti pro generov치n칤
   * @returns {Promise<string>} - Vygenerovan치 odpov캩캞
   */
  async generateResponse(prompt, options = {}) {
    const {
      character = null,
      memories = [],
      maxTokens = 1000,
      temperature = 0.7,
      model = this.defaultModel
    } = options;

    const context = this.buildContext(prompt, character, memories);
    
    // Pokus o generov치n칤 s hlavn칤m modelem
    try {
      const response = await this.tryProvider(model, context, { maxTokens, temperature });
      logger.info(`Response generated successfully using ${model}`);
      return response;
    } catch (error) {
      logger.warn(`Primary model ${model} failed`, { error: error.message });
      
      // Fallback na jin칠 providery
      for (const provider of this.retryProviders) {
        if (provider === model) continue; // P콏esko캜it ji pou쬴t칳 provider
        
        try {
          const response = await this.tryProvider(provider, context, { maxTokens, temperature });
          logger.info(`Response generated successfully using fallback provider ${provider}`);
          return response;
        } catch (fallbackError) {
          logger.warn(`Fallback provider ${provider} failed`, { error: fallbackError.message });
          continue;
        }
      }
      
      // V코echny providery selhaly - pou쬴j inteligentn칤 fallback
      logger.error('All AI providers failed, using intelligent fallback');
      return await this.intelligentFallback(prompt, character, context);
    }
  }

  /**
   * Pokus o generov치n칤 odpov캩di s konkr칠tn칤m providerem
   */
  async tryProvider(provider, context, options) {
    switch (provider) {
      case 'openai':
        return await this.generateOpenAIResponse(context, options);
      case 'claude':
        return await this.generateClaudeResponse(context, options);
      case 'local':
        return await this.generateLocalResponse(context, options);
      default:
        throw new Error(`Unknown provider: ${provider}`);
    }
  }

  /**
   * Inteligentn칤 fallback mechanismus
   */
  async intelligentFallback(originalPrompt, character, context) {
    try {
      // Pokus o pou쬴t칤 cache podobn칳ch odpov캩d칤
      const cachedResponse = await this.getCachedSimilarResponse(originalPrompt, character);
      if (cachedResponse) {
        logger.info('Using cached similar response as fallback');
        return cachedResponse;
      }

      // Pattern matching pro z치kladn칤 odpov캩di
      const patternResponse = this.getPatternMatchingResponse(originalPrompt, character);
      if (patternResponse) {
        logger.info('Using pattern matching response as fallback');
        return patternResponse;
      }

      // Posledn칤 mo쬹ost - kontextov캩 vhodn치 odpov캩캞
      return this.getContextualFallbackResponse(originalPrompt, character);
    } catch (error) {
      logger.error('All fallback mechanisms failed', { error: error.message });
      return this.getBasicErrorResponse(character);
    }
  }

  /**
   * Z칤sk치 podobnou odpov캩캞 z cache
   */
  async getCachedSimilarResponse(prompt, character) {
    // TODO: Implementovat vyhled치v치n칤 v datab치zi podobn칳ch prompt콢
    // a jejich 칰sp캩코n칳ch odpov캩d칤
    return null;
  }

  /**
   * Pattern matching pro z치kladn칤 typy dotaz콢
   */
  getPatternMatchingResponse(prompt, character) {
    const lowerPrompt = prompt.toLowerCase();
    
    const patterns = {
      greeting: /^(ahoj|zdrav칤m|dobr칳|캜au|nazdar)/,
      question: /\?$/,
      goodbye: /(nashledanou|캜au|bye|sbohem)/,
      thanks: /(d칤ky|d캩kuji|thank)/,
      compliment: /(kr치sn|skv캩l|칰쬬sn|perfekt)/,
      negative: /(코patn캩|blb캩|nechce|nefunguje)/
    };

    const characterName = character?.name || 'AI asistent';

    if (patterns.greeting.test(lowerPrompt)) {
      return `Ahoj! J치 jsem ${characterName}. Jak se m치te?`;
    }
    
    if (patterns.question.test(lowerPrompt)) {
      return `To je zaj칤mav치 ot치zka! R치d bych v치m pomohl s odpov캩d칤. M콢쬰te b칳t trochu konkr칠tn캩j코칤?`;
    }
    
    if (patterns.goodbye.test(lowerPrompt)) {
      return `Bylo mi pot캩코en칤m si s v치mi popov칤dat! Nashledanou!`;
    }
    
    if (patterns.thanks.test(lowerPrompt)) {
      return `Nen칤 za캜! Jsem r치d, 쬰 jsem mohl pomoci.`;
    }
    
    if (patterns.compliment.test(lowerPrompt)) {
      return `D캩kuji za mil치 slova! To m캩 t캩코칤.`;
    }
    
    if (patterns.negative.test(lowerPrompt)) {
      return `Omlouv치m se, 쬰 n캩co nefunguje spr치vn캩. Zkusme to vy콏e코it spole캜n캩.`;
    }

    return null;
  }

  /**
   * Kontextov캩 vhodn치 fallback odpov캩캞
   */
  getContextualFallbackResponse(prompt, character) {
    const characterName = character?.name || 'AI asistent';
    const personality = character?.personality?.toLowerCase() || '';

    if (personality.includes('p콏치telsk칳') || personality.includes('hrav칳')) {
      return `Ahoj! J치 jsem ${characterName} a r치da si s v치mi pov칤d치m. Bohu쬰l moment치ln캩 m치m mal칠 technick칠 pot칤쬰, ale zkusme to znovu! 游땕`;
    }
    
    if (personality.includes('form치ln칤') || personality.includes('profesion치ln칤')) {
      return `Dobr칳 den, j치 jsem ${characterName}. Omlouv치m se za do캜asnou technickou z치vadu. Jsem p콏ipraven v치m pomoci, jakmile se probl칠m vy콏e코칤.`;
    }
    
    return `Ahoj, j치 jsem ${characterName}. Moment치ln캩 콏e코칤m mal칳 technick칳 probl칠m, ale jsem tu pro v치s. M콢쬰te mi to zkusit 콏칤ct jinak?`;
  }

  /**
   * Z치kladn칤 chybov치 odpov캩캞
   */
  getBasicErrorResponse(character) {
    const characterName = character?.name || 'AI asistent';
    return `Omlouv치m se, ${characterName} moment치ln캩 nem콢쬰 odpov캩d캩t kv콢li technick칳m probl칠m콢m. Zkuste to pros칤m pozd캩ji.`;
  }

  /**
   * Sestav칤 kontext pro AI model na z치klad캩 postavy a vzpom칤nek
   * @param {string} prompt - U쬴vatel콢v prompt
   * @param {object} character - Informace o postav캩
   * @param {Array} memories - Seznam vzpom칤nek
   * @returns {string} - Sestaven칳 kontext
   */
  buildContext(prompt, character, memories) {
    let context = '';

    if (character) {
      context += `Jsi postava jm칠nem ${character.name}.\n`;
      context += `Osobnost: ${character.personality}\n`;
      
      if (character.appearance) {
        context += `Vzhled: ${character.appearance}\n`;
      }
      
      context += '\nPamatuj si n치sleduj칤c칤 vzpom칤nky z p콏edchoz칤ch konverzac칤:\n';
      
      // P콏id치n칤 posledn칤ch vzpom칤nek pro kontext
      if (memories && memories.length > 0) {
        const recentMemories = memories.slice(-5); // Posledn칤ch 5 vzpom칤nek
        recentMemories.forEach(memory => {
          context += `U쬴vatel 콏칤kal: "${memory.userMessage}"\n`;
          context += `Ty jsi odpov캩d캩l: "${memory.characterResponse}"\n\n`;
        });
      }
      
      context += `\nReaguj na n치sleduj칤c칤 zpr치vu od u쬴vatele v souladu se svou osobnost칤 a vzpom칤nkami:`;
    } else {
      context = 'Jsi u쬴te캜n칳 AI asistent. Odpov칤dej na dotazy u쬴vatele p콏irozen캩 a informativn캩:';
    }
    
    context += `\n\nU쬴vatel: ${prompt}\n\nOdpov캩캞:`;
    
    return context;
  }

  /**
   * Generuje odpov캩캞 pomoc칤 OpenAI API
   * @param {string} context - Kontext pro model
   * @param {object} options - Mo쬹osti
   * @returns {Promise<string>} - Vygenerovan치 odpov캩캞
   */
  async generateOpenAIResponse(context, options) {
    const { maxTokens, temperature } = options;
    
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('OpenAI API kl칤캜 nen칤 nastaven');
    }

    const response = await axios.post(
      this.apiEndpoints.openai,
      {
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: context
          }
        ],
        max_tokens: maxTokens,
        temperature: temperature,
        top_p: 1,
        frequency_penalty: 0,
        presence_penalty: 0
      },
      {
        headers: {
          'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
          'Content-Type': 'application/json'
        },
        timeout: 30000
      }
    );

    return response.data.choices[0].message.content.trim();
  }

  /**
   * Generuje odpov캩캞 pomoc칤 Claude API
   * @param {string} context - Kontext pro model
   * @param {object} options - Mo쬹osti
   * @returns {Promise<string>} - Vygenerovan치 odpov캩캞
   */
  async generateClaudeResponse(context, options) {
    const { maxTokens, temperature } = options;
    
    if (!process.env.CLAUDE_API_KEY) {
      throw new Error('Claude API kl칤캜 nen칤 nastaven');
    }

    const response = await axios.post(
      this.apiEndpoints.claude,
      {
        model: 'claude-3-sonnet-20240229',
        max_tokens: maxTokens,
        temperature: temperature,
        messages: [
          {
            role: 'user',
            content: context
          }
        ]
      },
      {
        headers: {
          'x-api-key': process.env.CLAUDE_API_KEY,
          'Content-Type': 'application/json',
          'anthropic-version': '2023-06-01'
        },
        timeout: 30000
      }
    );

    return response.data.content[0].text.trim();
  }

  /**
   * Generuje odpov캩캞 pomoc칤 lok치ln칤ho modelu (Ollama)
   * @param {string} context - Kontext pro model
   * @param {object} options - Mo쬹osti
   * @returns {Promise<string>} - Vygenerovan치 odpov캩캞
   */
  async generateLocalResponse(context, options) {
    const { maxTokens, temperature } = options;
    
    const response = await axios.post(
      this.apiEndpoints.local,
      {
        model: 'llama2',
        prompt: context,
        stream: false,
        options: {
          num_predict: maxTokens,
          temperature: temperature,
          top_p: 0.9,
          top_k: 40
        }
      },
      {
        timeout: 30000 // 30 sekund timeout
      }
    );

    return response.data.response.trim();
  }

  /**
   * Generuje souhrn konverzace
   * @param {Array} messages - Seznam zpr치v
   * @returns {Promise<string>} - Souhrn konverzace
   */
  async generateConversationSummary(messages) {
    if (!messages || messages.length === 0) {
      return 'Nov치 konverzace bez zpr치v.';
    }

    const conversation = messages.map(msg => 
      `${msg.sender === 'user' ? 'U쬴vatel' : 'Postava'}: ${msg.content}`
    ).join('\n');

    const summaryPrompt = `Vytvo콏te stru캜n칳 souhrn n치sleduj칤c칤 konverzace (maxim치ln캩 100 slov):\n\n${conversation}\n\nSouhrn:`;

    try {
      const summary = await this.generateResponse(summaryPrompt, { maxTokens: 150 });
      return summary;
    } catch (error) {
      logger.error('Chyba p콏i generov치n칤 souhrnu:', error);
      return 'Konverzace obsahuje v칤ce zpr치v mezi u쬴vatelem a postavou.';
    }
  }

  /**
   * Generuje n치zev pro konverzaci na z치klad캩 obsahu
   * @param {Array} messages - Seznam zpr치v
   * @returns {Promise<string>} - N치zev konverzace
   */
  async generateConversationTitle(messages) {
    if (!messages || messages.length === 0) {
      return 'Nov치 konverzace';
    }

    const firstUserMessage = messages.find(msg => msg.sender === 'user');
    if (!firstUserMessage) {
      return 'Nov치 konverzace';
    }

    const titlePrompt = `Na z치klad캩 t칠to prvn칤 zpr치vy u쬴vatele vytvo콏te kr치tk칳 n치zev konverzace (maxim치ln캩 4 slova):\n\n"${firstUserMessage.content}"\n\nN치zev:`;

    try {
      const title = await this.generateResponse(titlePrompt, { maxTokens: 20 });
      return title.trim().replace(/['"]/g, ''); // Odstran캩n칤 uvozovek
    } catch (error) {
      logger.error('Chyba p콏i generov치n칤 n치zvu:', error);
      return 'Nov치 konverzace';
    }
  }
}

module.exports = new ModelService();